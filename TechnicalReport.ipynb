{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 . Problem statement\n",
    "\n",
    "The recommeder systems have been growing in popularity. [In my article on medium](https://medium.com/p/810eec938d84/edit)  I've. described what recommender are the reasons why they are gaining popularity.\n",
    "\n",
    "The goal of this project was to explore and understand various approaches in  building a reommender systems and\n",
    "build a book recommender engine using data aboud books and ratings and user preferences and other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Collection\n",
    "\n",
    "## About original data\n",
    "My primary  books data set was inspired and adapted from [Kaggle](https://github.com/zygmuntz/goodbooks-10k) from zygmuntz.\n",
    "The dataset has 10k books and over five million ratings from 50k users or so.\n",
    "The data also had user defined tags.\n",
    "The books were  not latest  in 2020 and the newest books were published in 2017.\n",
    "\n",
    "\n",
    "## Adaptations to data\n",
    "The data was collected from GoodReads -  I decided to make few additions to the existing data to get\n",
    "* description , \n",
    "* number of pages and \n",
    "* if the book was e-book ,\n",
    "using the (Goodreads Python package)[https://pypi.org/project/Goodreads/] , which  provides a Python interface for the Goodreads API. Using it, you can do pretty much anything that Goodreads allows to do with their own data.\n",
    "\n",
    "At later phase in the project  I decided to pull newer books using topic, title etc to add more recent books to the collection.\n",
    "The Data collection work was organized is  [Jupyter Notebook](https://github.com/meghazavar/goodreads_book_recommender/blob/master/code/goodreads_data_gathering.ipynb) and  a [supporting python class](https://github.com/meghazavar/goodreads_book_recommender/blob/master/code/goodreads_data_gather.py)\n",
    "\n",
    "\n",
    "## Additional data collection\n",
    "For building 'knowledge based' recommender, I needed to collect the user preferences and incorporate them in to the model.\n",
    "For that purpose I designed a google survery to accept handful of data about user's reading habbits and integrated with Pandas dataframe so they could be pulled  directly for analysis. The work is organized  in  (survery)[https://forms.gle/PaGdtau71CEePde86] and [jupyter notebook](https://github.com/meghazavar/goodreads_book_recommender/blob/master/code/gather_book_data_google_survey.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data cleaning   \n",
    "\n",
    "This involved following  and work is organized under the [jupyter notebook](http://localhost:8888/notebooks/ga/projects/goodreads_book_recommender/code/goodreads_data_gathering.ipynb)\n",
    "* removing unused fields like  text review counts ,isbn3 , individual rating count, original_title\n",
    "* filling in  description for handful of fields as \n",
    "* converting publishing year to numeric and also  cukding them by decade\n",
    "* Genre were cleaned to combine  in to smaller range of borader genre.\n",
    "* duplicate titles were deduped  \n",
    "* as most of the books are in  english , categoried them as english and other for  further anlysis\n",
    "* deleted the records with **NO** ratings\n",
    "\n",
    "## 3.2 Data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books\n",
    "|column   |type   | description  |\n",
    "|---|---|---|\n",
    "|  bookID | int64  |  book dequence identifier | \n",
    "|  goodreads_book_id | int64  |  book  identifier for 'goodreads' API | \n",
    "|  title | object  |  Title of the book | \n",
    "|  authors | object  | Authors of the book  | \n",
    "|  is_ebook |  object | if the book is digital or printed  | \n",
    "|  description| object  | A short description about the book content  |  \n",
    "|  language_code | object  | primary language of the book  |\n",
    "| num_pages  | object  ||Number of pages the book contains   |\n",
    "| ratings_count  | int64 |Total number of ratings book received   |\n",
    "| text_reviews_count  | int64  |  total number of written text reviews book received | \n",
    "|average_rating |object | average rating of the book |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings\n",
    "|column   |type   | description  |\n",
    "|---|---|---|\n",
    "|  bookID | int64  |  book dequence identifier | \n",
    "|  user_id | int64  | 'goodreads' API  user identifier| \n",
    "|  rating | object  |  rating for the book by the user  on scale of 0-5 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### book_Genre\n",
    "|column   |type   | description  |\n",
    "|---|---|---|\n",
    "|  goodreads_book_id | int64  |  book  identifier for 'goodreads' API | \n",
    "|  tag_name | int64  | genre or userdefined tag for the book| \n",
    "\n",
    "Note : A book can have multiple tags associated with it, while not ideal  sometimes a boot has over 100s of tags associated with it.\n",
    "\n",
    "Alot of time was spent in cosolidating the tags where it made sense but it  has been an ongoing effort and due to limited time  I had to timebox this effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3  Data Exploration\n",
    "\n",
    "As part exploring dataset following are some of the questions that I explored "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average length of books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most Books are 150-400 pages\n",
    "#< todo : paste the  chart>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are book ratings enough?\n",
    "\n",
    "All the books had  atleast 1000 ratings making is really good  candidate for  collaborative  filter based model,\n",
    "where  the recommendation is mainly powered as a results of rating from the the other similar users\n",
    "< todo : paste the  chart>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating distribution\n",
    "\n",
    "<img src=\"images/book_rating_distribution.png\"> Averating rating distribution</img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People tend to rate book when they like book than when they dont\n",
    "\n",
    "It was interesting to see the bias that books with highr ratings are also have better ratings. I think this can be used as input to the 'Non personalised' recommder to  bring the top recommendations form the community\n",
    "\n",
    "<img src =\"images/rate_when_you_like.png\"> </img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do books have ratings from multiple users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how many users have rated more than 1 book?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Best selling authors\n",
    "(Authors with highest number of ratings - assuming that person who rated perhaps bought the books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo. include chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "Recommenders try to narrow down choices for people by presenting them with suggestions that they are most likely to buy or use.With a constantly increasing amount of content on the internet,filtering algorithms are now more relevant than ever. There areseveral different methods of providing this type of filtering.\n",
    "At high level recomemnders can be devided in following 4 categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Non Personalized Recommender\n",
    "The Level of personalization is none. The recommendations are made using the wisom of community.\n",
    "The non-personalised recommender are based on the premise that humans are flock animals and curious about community opinions. These are simple to build , requires no user information and can be great for anonymous users or when no user data is available.\n",
    "\n",
    "\n",
    "Typically some kind of summary statistics is used to make the recommendation. Other times external factors can be fed in to the system to make recommendations. \n",
    "I decided  to build  non-personalised recommnder using  3 Criterias as below . The work is organized in the [juputer notebook]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1.1. Top 20 highly rated  books\n",
    "<img src =\"images/top_20_highest_rated.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1.2 Top five best rated  books by genre\n",
    "<img src =\"images/top_5_best_rated_by_genre.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4.1.3 Recommendation based on  current  news\n",
    "\n",
    "I wanted  to build a scraper to get  top 5 treding events to determine the books,\n",
    "\n",
    "I used the http://redditlist.com/ lists to find fastest growing subreddits in last 24h or the most active subreddits for last 24h.I also noticed that You-tube feed contents and news were  focused around  corona virus.\n",
    "\n",
    "As it turns out Corono Virus  news is  probably  the highest on  everyone's mind.\n",
    "Note : I manually used  gnerated this based on research , and was not successful able to scrape the page.\n",
    "\n",
    "I think following the trend It would relevant to  recommend books on this topic. As the data set was old - I had to rerun the data collection module for this topic to gather books on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOP 10  books on COVID -19 Recommnded for you\n",
    "<img src =\"images/top-15-covid.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personalized Recommenders:\n",
    "These recommenders are fundamnetally based on some form of data that is genarted as a result of user-item interaction which typically is  some kind of rating a ordinal number  or a review which can be positive negative or neutral.\n",
    "They can be  further categoried as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative based Recommender (user based)\n",
    "Collaborative filtering relies on the  on the concept that similar users like similar things\n",
    "of the more commonly used are user based .  A user profile is generated  by comparing the ratings of the user with other users for the same product and based the \"similarity\" between the users , the books from  users with similar tasteare recommended that this user may not have used so far.\n",
    "\n",
    "\n",
    "<TBD>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item Based Collaborative Filtering (IB-CF) \n",
    "Recommendation based on calculating similarties of two items based on peoples rating of two items.\n",
    "\n",
    "This was adapted from GA recommender lesson. I primarily used the datframe ratings which has three columns,\n",
    "book_id , user_id and rating for the book by the user id.\n",
    "\n",
    "Note : given that we have 10K books rated by 50k users, it is very likely that books have ratings from multiple users.\n",
    "This helps in finding \"Similar books\"\n",
    "\n",
    "\n",
    "1. book-book matrix  was created where  rows were individual books and columns were books ,\n",
    "the value in corresponding cell (Bi,Bj) represented the similarity between  book i and bookj.\n",
    "\n",
    "The Similarity  is a score beween 0 to 1 and is detemined using the metric \"Pairwise distance\" which in turn is based off Cosine similarity.\n",
    "The score is determines using the priciple that Similar vectors have same direction where the direction is determined is using rating as an angle.\n",
    "The pairwise distance is smaller between similar items and as the distance increases the items are less similar.\n",
    "\n",
    "\n",
    "So for example\n",
    "         \n",
    "||Matt|Amy |Charlie|Rob| Bob| Rita |\n",
    "|---|---|---|---|---|---|---|\n",
    "||book1| 5  |  5    | 3 |  1  |  ?  |\n",
    "||book2| ?  |   2   | 3 |  3  |  4  |\n",
    "||book3|5   |  4    |   |  1  |  5  |\n",
    "\n",
    "\n",
    "in order to find similarity between. Book 1 and Book 2\n",
    "Cosine(Book1, Book2)\n",
    "\n",
    "v1 =  5 C + 3 R + 1 B\n",
    "\n",
    "v2 = 2 C + 3 R + 3 B\n",
    "\n",
    "Therefore Cosine Similarity between movies book1 and book2 is  for Amy:\n",
    "cos(v1,v2) = (5*2 + 3*3 + 1*3) / sqrt[(25+9+1) * (4+9+9)] = 0.792\n",
    "\n",
    "With cosine similarity of higher means closer. so AMY might like it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Based Collaborative Filtering (UB-CF) : Recommendations based on the calculating similarities of two users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based Recommender (item based)\n",
    "\n",
    "Item based (content based ) where User's past purchase history or activity is user to create a user profile against the  features of the product and  product recommendations are generated based on product with similar features that user prefer. The work is organized in [jupyter notebook](https://github.com/meghazavar/goodreads_book_recommender/blob/master/code/CollaborativeItemBasedRecommender.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Title |Author |Score |Cluster|Book id| |\n",
    "|---|---|---|---|---|--|\n",
    "| Homicidal Psycho Jungle Cat  | Bill Watterson  |  -  |5 |\n",
    "|The Essential Calvin and Hobbes: A Calvin and Hobbes Treasury | Bill Watterson | 0.37 | 5  |\n",
    "|The Authoritative Calvin and Hobbes: A Calvin and Hobbes Treasury | Bill Watterson | 0.32 | 5|  \n",
    "|Calvin and Hobbes | Bill Watterson, G.B. Trudeau | 0.32 | 5 |\n",
    "|---|---|---|---|\n",
    "|=>The Lord of the Rings (The Lord of the Rings, #1-3)| J.R.R. Tolkien |  | 5 | 189  \n",
    "|The Fellowship of the Ring (The Lord of the Rings, #1) | J.R.R. Tolkien | 0.78 | 5| 19 \n",
    "|J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings | J.R.R. Tolkien | 0.51 | 5| 964 \n",
    "|---|---|---|---|\n",
    "|=>Naked Economics: Undressing the Dismal Science| Charles Wheelan |  | 4 | 8084  \n",
    "|Economics in One Lesson: The Shortest & Surest Way to Understand Basic Economics | Henry Hazlitt | 0.12 | 5| 9732 \n",
    "|Thirteen Moons | Charles Frazier | 0.1 | 2| 9928 \n",
    "|When Crickets Cry | Charles Martin | 0.1 | 5| 9096 \n",
    "|---|---|---|---|\n",
    "|=>Python for Data Analysis| [Wes McKinney] |  | 4 | 10056  \n",
    "|Python Data Science Handbook: Tools and Techniques for Developers | [Jake Vanderplas] | 0.56 | 5| 10053 \n",
    "|Python Cookbook | [David Beazley, Brian K. Jones] | 0.54 | 4| 10052 \n",
    "|Data Visualization: A Practical Introduction | [Kieran Healy] | 0.51 | 5| 10021 \n",
    "|---|---|---|---|\n",
    "|=>You Are a Badass| [Rachel Hollis, Jen Sincero] |  | 3 | 10032  \n",
    "|Girl, Wash Your Face / Girl, Stop Apologizing | [Rachel Hollis] | 0.46 | 3| 10031 \n",
    "|Girl, Wash Your Face: Stop Believing the Lies about Who You Are So You Can Become Who You Were Meant to Be | [Rachel Hollis] | 0.38 | 3| 10033 \n",
    "|You Are a Badass: How to Stop Doubting Your Greatness and Start Living an Awesome Life | Jen Sincero | 0.29 | 4| 6071\n",
    "|---|---|---|---|\n",
    "|=>First Among Equals| Jeffrey Archer |  | 3 | 8399  \n",
    "|Paths of Glory | Jeffrey Archer | 0.51 | 3| 7889 \n",
    "|The Fourth Estate | Jeffrey Archer | 0.51 | 3| 9628 \n",
    "|False Impression | Jeffrey Archer | 0.51 | 2| 8199 \n",
    "|---|---|---|---|\n",
    "|=>Lean Mean Thirteen (Stephanie Plum, #13)| Janet Evanovich |  | 4 | 1694  \n",
    "|Fearless Fourteen (Stephanie Plum, #14) | Janet Evanovich | 0.6 | 4| 1821 \n",
    "|Twelve Sharp (Stephanie Plum, #12) | Janet Evanovich | 0.6 | 4| 1627 \n",
    "|بيكاسو وستاربكس | ياسر حارب | 0.58 | 2| 5373 \n",
    "|---|---|---|---|\n",
    "|=>The Vampire's Assistant (Cirque Du Freak, #2)| Darren Shan |  | 4 | 3577  \n",
    "|The Vampire Prince (Cirque Du Freak, #6) | Darren Shan | 0.57 | 5| 5159 \n",
    "|Vampire Mountain (Cirque Du Freak, #4) | Darren Shan | 0.55 | 4| 4514 \n",
    "|A Living Nightmare (Cirque Du Freak, #1) | Darren Shan | 0.53 | 4| 2759 \n",
    "|---|---|---|---|\n",
    "|=>Insurgent (Divergent, #2)| Veronica Roth |  | 4 | 69  \n",
    "|Divergent Series Complete Box Set (Divergent, #1-3) | Veronica Roth | 0.51 | 5| 2880 \n",
    "|---|---|---|---|\n",
    "|=>First Among Equals| Jeffrey Archer |  | 3 | 8399  \n",
    "|Paths of Glory | Jeffrey Archer | 0.51 | 3| 7889 \n",
    "|The Fourth Estate | Jeffrey Archer | 0.51 | 3| 9628 \n",
    "|False Impression | Jeffrey Archer | 0.51 | 2| 8199 \n",
    "|---|---|---|---|\n",
    "|=>The Complete Sherlock Holmes| Arthur Conan Doyle |  | 5 | 769  \n",
    "|The Complete Sherlock Holmes, Vol 2 | Arthur Conan Doyle, Kyle Freeman | 0.9 | 5| 1320 \n",
    "|Sherlock Holmes: The Complete Novels and Stories, Volume I | Arthur Conan Doyle | 0.79 | 5| 5508 \n",
    "|The Adventures of Sherlock Holmes | Arthur Conan Doyle | 0.67 | 5| 514 \n",
    "|---|---|---|---|\n",
    "|=>Visions of Heat (Psy-Changeling #2)| Nalini Singh |  | 4 | 7983  \n",
    "|Branded by Fire (Psy-Changeling #6) | Nalini Singh | 0.6 | 5| 8267 \n",
    "|Mine to Possess (Psy-Changeling #4) | Nalini Singh | 0.6 | 4| 9593 \n",
    "|Kiss of Snow (Psy-Changeling #10) | Nalini Singh | 0.55 | 5| 8408 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge based recommender\n",
    "\n",
    "Suggests products based on inferences about a\n",
    "userʼs needs and preferences\n",
    "! Functional knowledge: about how a particular item\n",
    "meets a particular user need\n",
    "! The user model can be any knowledge structure that\n",
    "supports this inference\n",
    "\" A query, i.e., the set of preferred features for a\n",
    "product\n",
    "\" A case (in a case-based reasoning system)\n",
    "\" An adapted similarity metric (for matching)\n",
    "\" A part of an ontology\n",
    "! There is a large use of domain knowledge\n",
    "encoded in a knowledge representation\n",
    "language/approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Ideas\n",
    "\n",
    "Include  Model based collaborative  filtering, Examples of such model-based methods include decision trees, rule-based models, Bayesian methods and latent factor models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
