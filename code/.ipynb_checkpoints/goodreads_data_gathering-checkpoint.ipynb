{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Installing and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: betterreads in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: xmltodict in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages/xmltodict-0.12.0-py3.7.egg (from betterreads) (0.12.0)\n",
      "Requirement already satisfied: backports-datetime-fromisoformat in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from betterreads) (1.0.0)\n",
      "Requirement already satisfied: rauth in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages/rauth-0.7.3-py3.7.egg (from betterreads) (0.7.3)\n",
      "Requirement already satisfied: requests in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from betterreads) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install betterreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data... \n",
      "[  728   977   992 ...  9998  9999 10000]\n",
      "getting 1 out of missing 2354 descriptions\n",
      "728,Brown Bear, Brown Bear, What Do You See?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from betterreads import client\n",
    "from goodreads_data_gather import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data... \n"
     ]
    }
   ],
   "source": [
    "h = helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note : Only run this very first run so we can get the orginal books set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the books dataframe is (10000, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['book_id', 'goodreads_book_id', 'best_book_id', 'work_id',\n",
       "       'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year',\n",
       "       'original_title', 'title', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'image_url', 'small_image_url', 'description', 'num_pages', 'e_book'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# books = pd.read_csv('../data/books.csv')\n",
    "# print( f\"shape of the books dataframe is {books.shape}\")\n",
    "# #We are going to add. 3 more columns and populate them using the GoodReads client\n",
    "# books['description'] =np.nan\n",
    "# books['num_pages'] =0\n",
    "# books['e_book'] =False\n",
    "# books.to_csv(\"../data/books_desc.csv\", index=False)\n",
    "# books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the ratings dataframe is (5976479, 3)\n",
      "shape of the books_tags dataframe is (999912, 3)\n",
      "shape of the tags dataframe is (34252, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>e_book</th>\n",
       "      <th>is_ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "      <td>Could you survive on your own, in the wild, wi...</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "\n",
       "         isbn13          authors  original_publication_year    original_title  \\\n",
       "0  9.780439e+12  Suzanne Collins                     2008.0  The Hunger Games   \n",
       "\n",
       "   ... ratings_2 ratings_3  ratings_4  ratings_5  \\\n",
       "0  ...    127936    560092    1481305    2706317   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "\n",
       "                                     small_image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603s...   \n",
       "\n",
       "                                         description  num_pages  e_book  \\\n",
       "0  Could you survive on your own, in the wild, wi...        374   False   \n",
       "\n",
       "   is_ebook  \n",
       "0     False  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books =pd.read_csv(\"../data/books_desc.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "print( f\"shape of the ratings dataframe is {ratings.shape}\")\n",
    "\n",
    "book_tags = pd.read_csv(\"../data/book_tags.csv\")\n",
    "print( f\"shape of the books_tags dataframe is {book_tags.shape}\")\n",
    "\n",
    "tags = pd.read_csv(\"../data/tags.csv\")\n",
    "print( f\"shape of the tags dataframe is {tags.shape}\")\n",
    "\n",
    "### Combining booktag ids with the actual names\n",
    "pd.merge(left=book_tags,right =tags, how =\"left\", on ='tag_id')\n",
    "book_tags.to_csv(\"../data/book_tags_combined\",index =False)\n",
    "book_tags = pd.read_csv(\"../data/book_tags_combined.csv\")\n",
    "books.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_id</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag_id tag_name\n",
       "0       0        -"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30574</td>\n",
       "      <td>167697</td>\n",
       "      <td>to-read</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goodreads_book_id  tag_id   count tag_name\n",
       "0                  1   30574  167697  to-read"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We are going to populate description , num_of_pages and is_ebook from goodreads Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  728   977   992 ...  9998  9999 10000]\n",
      "getting 10 out of missing 4102 descriptions\n",
      "728,Brown Bear, Brown Bear, What Do You See?\n",
      "977,Inferno\n",
      "992,The Twilight Saga (Twilight, #1-4)\n",
      "994,All Creatures Great and Small (All Creatures Great and Small, #1)\n",
      "1108,The Complete Fairy Tales\n",
      "1113,Thus Spoke Zarathustra\n",
      "1329,Howl and Other Poems\n",
      "1338,The Book of Mormon: Another Testament of Jesus Christ\n",
      "1382,Anne Rice's The Vampire Lestat: A Graphic Novel\n",
      "1432,The Communist Manifesto\n"
     ]
    }
   ],
   "source": [
    "books =h.fill_missing_columns(\"../data/books_desc.csv\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "585 books that are missing orig title, replace them with title\n",
    "book = gc.book(3)\n",
    "book.original_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting  recent books  based on Denver DSI classmates reading preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading book Learning Python for topic python\n",
      "Downloading book Python Cookbook for topic python\n",
      "Downloading book Python for Data Analysis for topic python\n",
      "Downloading book Programming Python for topic python\n",
      "Downloading book The Greedy Python for topic python\n",
      "Downloading book Python Machine Learning for topic python\n",
      "Downloading book Python for Everybody: Exploring Data in Python 3 for topic python\n",
      "Downloading book Effective Python: 59 Specific Ways to Write Better Python for topic python\n",
      "Downloading book Black Hat Python: Python Programming for Hackers and Pentesters for topic python\n",
      "Downloading book Monty Python Speaks! for topic python\n",
      "Downloading book Python for Kids for topic python\n",
      "Downloading book Python Pocket Reference for topic python\n",
      "Downloading book A Game of Thrones (A Song of Ice and Fire, #1) for topic of Thrones\n",
      "Downloading book Crown of Midnight (Throne of Glass, #2) for topic of Thrones\n",
      "Downloading book Heir of Fire (Throne of Glass, #3) for topic of Thrones\n",
      "Downloading book Queen of Shadows (Throne of Glass, #4) for topic of Thrones\n",
      "Downloading book Kingdom of Ash (Throne of Glass, #7) for topic of Thrones\n",
      "Downloading book Tower of Dawn (Throne of Glass, #6) for topic of Thrones\n",
      "Downloading book The World of Throne of Glass for topic of Thrones\n",
      "Downloading book A Game Of Thrones preview for topic of Thrones\n",
      "Downloading book The Throne of Fire (The Kane Chronicles, #2) for topic of Thrones\n",
      "Downloading book The World of Ice & Fire: The Untold History of Westeros and the Game of Thrones for topic of Thrones\n",
      "Downloading book The Assassin's Blade (Throne of Glass, #0.1-0.5) for topic of Thrones\n",
      "Downloading book The Name of the Wind (The Kingkiller Chronicle, #1) for topic Patrick Rothfuss\n",
      "Downloading book The Wise Man's Fear (The Kingkiller Chronicle, #2) for topic Patrick Rothfuss\n",
      "Downloading book The Slow Regard of Silent Things (The Kingkiller Chronicle, #2.5) for topic Patrick Rothfuss\n",
      "Downloading book Doors of Stone (The Kingkiller Chronicle, #3) for topic Patrick Rothfuss\n",
      "Downloading book The Thing Beneath the Bed (The Adventures of the Princess and Mr. Whiffle #1) for topic Patrick Rothfuss\n",
      "Downloading book The Lightning Tree for topic Patrick Rothfuss\n",
      "Downloading book O Medo do Homem Sábio - Parte 1 (A Crónica do Regicida, Livro 2 - Parte 1) for topic Patrick Rothfuss\n",
      "Downloading book O Medo do Homem Sábio - Parte 2 (A Crónica do Regicida, Livro 2 - Parte 2) for topic Patrick Rothfuss\n",
      "Downloading book Rick and Morty vs. Dungeons & Dragons for topic Patrick Rothfuss\n",
      "Downloading book A Song of Ice and Fire (A Song of Ice and Fire, #1-5) for topic A Song of Ice and Fire\n",
      "Downloading book A Song of Ice and Fire (A Song of Ice and Fire, #1-4) for topic A Song of Ice and Fire\n",
      "Downloading book A Game of Thrones (A Song of Ice and Fire, #1) for topic A Song of Ice and Fire\n",
      "Downloading book A Clash of Kings  (A Song of Ice and Fire, #2) for topic A Song of Ice and Fire\n",
      "Downloading book A Storm of Swords (A Song of Ice and Fire, #3) for topic A Song of Ice and Fire\n",
      "Downloading book A Feast for Crows (A Song of Ice and Fire, #4) for topic A Song of Ice and Fire\n",
      "Downloading book A Storm of Swords: Blood and Gold (A Song of Ice and Fire, #3: Part 2 of 2) for topic A Song of Ice and Fire\n",
      "Downloading book A Storm of Swords: Steel and Snow (A Song of Ice and Fire, #3: Part 1 of 2) for topic A Song of Ice and Fire\n",
      "Downloading book A Song of Ice and Fire Books for topic A Song of Ice and Fire\n",
      "Downloading book A Dance with Dragons: Dreams and Dust (A Song of Ice and Fire, #5, Part 1 of 2) for topic A Song of Ice and Fire\n",
      "Downloading book A Song of Ice and Fire Roleplaying for topic A Song of Ice and Fire\n",
      "Downloading book A Song of Ice and Fire: George R. R. Martin, World of a Song of Ice and Fire, Major Houses in a Song of Ice and Fire for topic A Song of Ice and Fire\n",
      "Downloading book A Dance with Dragons 2: After the Feast (A Song of Ice and Fire, #5, Part 2 of 2) for topic A Song of Ice and Fire\n",
      "Downloading book A Game of Thrones: The Graphic Novel, Volume One (A Song of Ice and Fire: The Graphic Novels, #1) for topic A Song of Ice and Fire\n",
      "Downloading book Articles about A Song Of Ice And Fire for topic A Song of Ice and Fire\n",
      "Downloading book Knots and Crosses (Inspector Rebus, #1) for topic Inspector Rebus\n",
      "Downloading book Exit Music (Inspector Rebus, #17) for topic Inspector Rebus\n",
      "Downloading book Resurrection Men (Inspector Rebus, #13) for topic Inspector Rebus\n",
      "Downloading book Strip Jack (Inspector Rebus, #4) for topic Inspector Rebus\n",
      "Downloading book Mortal Causes (Inspector Rebus, #6) for topic Inspector Rebus\n",
      "Downloading book Let It Bleed (Inspector Rebus, #7) for topic Inspector Rebus\n",
      "Downloading book Dead Souls (Inspector Rebus, #10) for topic Inspector Rebus\n",
      "Downloading book Hide and Seek (Inspector Rebus, #2) for topic Inspector Rebus\n",
      "Downloading book Black and Blue (Inspector Rebus, #8) for topic Inspector Rebus\n",
      "Downloading book Tooth and Nail (Inspector Rebus, #3) for topic Inspector Rebus\n",
      "Downloading book The Black Book (Inspector Rebus, #5) for topic Inspector Rebus\n",
      "Downloading book The Hanging Garden (Inspector Rebus, #9) for topic Inspector Rebus\n",
      "Downloading book Set in Darkness (Inspector Rebus, #11) for topic Inspector Rebus\n",
      "Downloading book Standing in Another Man's Grave (Inspector Rebus, #18) for topic Inspector Rebus\n",
      "Downloading book Saints of the Shadow Bible (Inspector Rebus, #19) for topic Inspector Rebus\n",
      "Downloading book The Naming of the Dead (Inspector Rebus, #16) for topic Inspector Rebus\n",
      "Downloading book In a House of Lies (Inspector Rebus, #22) for topic Inspector Rebus\n",
      "Downloading book Inspector Rebus CD Collection (Inspector Rebus, #13-15) for topic Inspector Rebus\n",
      "Downloading book Doing Data Science for topic Data Science\n",
      "Downloading book Data Science for topic Data Science\n",
      "Downloading book Data Smart: Using Data Science to Transform Information into Insight for topic Data Science\n",
      "Downloading book Data Science for Business: What you need to know about data mining and data-analytic thinking for topic Data Science\n",
      "Downloading book Practical Data Science with R for topic Data Science\n",
      "Downloading book Python Data Science Handbook: Tools and Techniques for Developers for topic Data Science\n",
      "Downloading book Practical Data Science Cookbook for topic Data Science\n",
      "Downloading book Machine Learning: New and Collected Stories for topic mechine learning\n",
      "Downloading book Storytelling with Data: A Data Visualization Guide for Business Professionals for topic Data Visualization\n",
      "Downloading book Interactive Data Visualization for the Web for topic Data Visualization\n",
      "Downloading book Data Visualization: A Practical Introduction for topic Data Visualization\n",
      "Downloading book Data Visualization: A Successful Design Process for topic Data Visualization\n",
      "Downloading book Designing Data Visualizations: Representing Informational Relationships for topic Data Visualization\n",
      "Downloading book Data Points: Visualization That Means Something for topic Data Visualization\n",
      "Downloading book Good Charts: The HBR Guide to Making Smarter, More Persuasive Data Visualizations for topic Data Visualization\n",
      "Downloading book Cool Infographics: Effective Communication with Data Visualization and Design for topic Data Visualization\n",
      "Downloading book Effective Data Visualization: The Right Chart for the Right Data for topic Data Visualization\n",
      "Downloading book Data Visualization: Principles and Practice for topic Data Visualization\n",
      "Downloading book Rich Dad, Poor Dad for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Cashflow Quadrant: Rich Dad's Guide to Financial Freedom for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Guide to Investing: What the Rich Invest in That the Poor and Middle Class Do Not! for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Increase Your Financial IQ: Get Smarter with Your Money for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Retire Young, Retire Rich: How to Get Rich Quickly and Stay Rich Forever! for topic Robert T. Kiyosaki\n",
      "Downloading book The Business School For People Who Like Helping People for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Before You Quit Your Job: 10 Real-Life Lessons Every Entrepreneur Should Know About Building a Multimillion-Dollar Business for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad Poor Dad for Teens: The Secrets about Money--That You Don't Learn in School! for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Conspiracy of the Rich: The 8 New Rules of Money for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Prophecy: Why the Biggest Stock Market Crash in History Is Still Coming...and How You Can Prepare Yourself and Profit from It! for topic Robert T. Kiyosaki\n",
      "Downloading book Why \"A\" Students Work for \"C\" Students and \"B\" Students Work for the Government: Rich Dad's Guide to Financial Education for Parents for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Rich Kid, Smart Kid: Giving Your Children a Financial Headstart for topic Robert T. Kiyosaki\n",
      "Downloading book Rich Dad's Who Took My Money?: Why Slow Investors Lose and Fast Money Wins! for topic Robert T. Kiyosaki\n",
      "Downloading book Second Chance: for Your Money, Your Life and Our World for topic Robert T. Kiyosaki\n",
      "Downloading book Unfair Advantage: The Power of Financial Education for topic Robert T. Kiyosaki\n",
      "Downloading book The Real Book of Real Estate: Real Experts. Real Stories. Real Life. for topic Robert T. Kiyosaki\n",
      "Downloading book A Summary of Rich Dad Poor Dad by Robert T. Kiyosaki for topic Robert T. Kiyosaki\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading book The Gifts of Imperfection for topic Brené Brown\n",
      "Downloading book Daring Greatly: How the Courage to Be Vulnerable Transforms the Way We Live, Love, Parent, and Lead for topic Brené Brown\n",
      "Downloading book Braving the Wilderness: The Quest for True Belonging and the Courage to Stand Alone for topic Brené Brown\n",
      "Downloading book Rising Strong for topic Brené Brown\n",
      "Downloading book Dare to Lead for topic Brené Brown\n",
      "Downloading book I Thought It Was Just Me: Women Reclaiming Power and Courage in a Culture of Shame for topic Brené Brown\n",
      "Downloading book The Gifts of Imperfect Parenting: Raising Children with Courage, Compassion, and Connection for topic Brené Brown\n",
      "Downloading book Men, Women, and Worthiness: The Experience of Shame and the Power of Being Enough for topic Brené Brown\n",
      "Downloading book Rising Strong as a Spiritual Practice for topic Brené Brown\n",
      "Downloading book Women & Shame: Reaching Out, Speaking Truths and Building Connection for topic Brené Brown\n",
      "Downloading book Connections: A 12-Session Psychoeducational Shame-Resilience Curriculum for topic Brené Brown\n",
      "Downloading book Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Mathematicians School Maths Dot Grid Journal, Diary, Notebook 6 x 9 inches with 120 Pages for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Funny Math Journal - Notebook - Workbook For Mathematics Teacher And Funny Pun Fan - 6x9 - 120 Blank Lined Pages for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Funny Math Journal Notebook Workbook For Mathematics Teacher And Funny Pun Fan - 6x9 - 120 Graph Paper Pages for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Funny Math Journal - Notebook - Workbook For Mathematics Teacher And Funny Pun Fan - 6x9 - 120 Blank Lined Pages for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Funny Math Journal Notebook Workbook For Mathematics Teacher And Funny Pun Fan - 6x9 - 120 Graph Paper Pages for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Mathematiker Schulmathematikerin Notizbuch liniert DIN A5 - 120 Seiten f�r Notizen, Zeichnungen, Formeln - Organizer Schreibheft Planer Tagebuch for topic weapons of math destruction\n",
      "Downloading book Weapons of Math Destruction: Mathematicians School Maths ruled Notebook 6x9 Inches - 120 lined pages for notes, drawings, formulas - Organizer writing book planner diary for topic weapons of math destruction\n",
      "Downloading book Girl, Wash Your Face / Girl, Stop Apologizing for topic Girl, Wash Your Face\n",
      "Downloading book Girl, Wash Your Face: Stop Believing the Lies about Who You Are So You Can Become Who You Were Meant to Be for topic Girl, Wash Your Face\n",
      "Downloading book Girl, Wash Your Face / Girl, Stop Apologizing / You Are a Badass for topic Girl, Wash Your Face\n",
      "Downloading book Summary of Girl, Wash your Face by Rachel Hollis: Conversation Starters for topic Girl, Wash Your Face\n",
      "Downloading book Recommender Systems: An Introduction for topic recommender systems\n",
      "Downloading book Recommender Systems Handbook for topic recommender systems\n",
      "Downloading book Recommender Systems: The Textbook for topic recommender systems\n",
      "Downloading book Statistical Methods for Recommender Systems for topic recommender systems\n",
      "Downloading book Recommender Systems for topic recommender systems\n",
      "Downloading book Collaborative Filtering Recommender Systems for topic recommender systems\n",
      "Downloading book Recommender Systems for Learning for topic recommender systems\n",
      "Downloading book Recommender Systems for topic recommender systems\n",
      "Downloading book Recommender Systems for topic recommender systems\n",
      "Downloading book Recommender System for topic recommender systems\n",
      "Downloading book Social Network-Based Recommender Systems for topic recommender systems\n",
      "Downloading book Recommender Systems for Social Tagging Systems for topic recommender systems\n",
      "Downloading book Recommender Systems for the Social Web for topic recommender systems\n"
     ]
    }
   ],
   "source": [
    "\n",
    "topics =['python','of Thrones','Patrick Rothfuss','A Song of Ice and Fire','Inspector Rebus',\n",
    "       'Data Science', 'mechine learning','Data Visualization','Robert T. Kiyosaki','Brené Brown',\n",
    "       'weapons of math destruction','Girl, Wash Your Face','recommender systems']\n",
    "for topic in topics :\n",
    "    df2 =h.get_books(topic)\n",
    "    books = pd.concat([books,df2],sort=True)\n",
    "books.reset_index(inplace=True, drop=True)  \n",
    "books.to_csv(\"../data/books_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Collecting  recent books  based on COVID-19 outbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df =pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading book Pandemic (The Extinction Files, #1) for topic Pandemic\n",
      "Downloading book Pandemic for topic Pandemic\n",
      "Downloading book Pandemic (Infected, #3) for topic Pandemic\n",
      "Downloading book Spillover: Animal Infections and the Next Human Pandemic for topic Pandemic\n",
      "Downloading book The Great Influenza: The Story of the Deadliest Pandemic in History for topic Pandemic\n",
      "Downloading book Jag (Pandemic Sorrow, #1) for topic Pandemic\n",
      "Downloading book The Jakarta Pandemic (The Perseid Collapse, #0.5) for topic Pandemic\n",
      "Downloading book Pandemic (Jack Stapleton & Laurie Montgomery, #11) for topic Pandemic\n",
      "Downloading book The China Pandemic (Graham's Resolution #1) for topic Pandemic\n",
      "Downloading book Pandemic (Dr. Noah Haldane, #1) for topic Pandemic\n",
      "Downloading book Pandemic: The Beginning (Pandemic #1) for topic Pandemic\n",
      "Downloading book Rush (Pandemic Sorrow, #2) for topic Pandemic\n",
      "Downloading book Pandemic: Tracking Contagions, from Cholera to Ebola and Beyond for topic Pandemic\n",
      "Downloading book Pandemic (The Survivors #1) for topic Pandemic\n",
      "Downloading book Pandemic (The Retreat, #1) for topic Pandemic\n",
      "Downloading book Pandemic (Paul Richter, #2) for topic Pandemic\n",
      "Downloading book Roxy (Pandemic Sorrow, #3) for topic Pandemic\n",
      "Downloading book Beginnings (Pandemic #1) for topic Pandemic\n",
      "Downloading book The Viral Storm: The Dawn of a New Pandemic Age for topic Pandemic\n",
      "Downloading book Frozen Pandemic: Apocalypse for topic Pandemic\n"
     ]
    }
   ],
   "source": [
    "topics =[ 'Pandemic']\n",
    "for topic in topics :\n",
    "    df =h.get_books(topic,strict=False)\n",
    "    covid_df = pd.concat([covid_df,df],sort=True)\n",
    "covid_df.reset_index(inplace=True, drop=True)  \n",
    "covid_df.to_csv(\"../data/covid_19_books_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics =['covid-19','Corona Virus' 'CoronaVirus','Pandemic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading book Pandemic (The Extinction Files, #1) for topic Pandemic\n",
      "Downloading book Pandemic for topic Pandemic\n",
      "Downloading book Pandemic (Infected, #3) for topic Pandemic\n",
      "Downloading book Spillover: Animal Infections and the Next Human Pandemic for topic Pandemic\n",
      "Downloading book The Great Influenza: The Story of the Deadliest Pandemic in History for topic Pandemic\n",
      "Downloading book Jag (Pandemic Sorrow, #1) for topic Pandemic\n",
      "Downloading book The Jakarta Pandemic (The Perseid Collapse, #0.5) for topic Pandemic\n",
      "Downloading book Pandemic (Jack Stapleton & Laurie Montgomery, #11) for topic Pandemic\n",
      "Downloading book The China Pandemic (Graham's Resolution #1) for topic Pandemic\n",
      "Downloading book Pandemic (Dr. Noah Haldane, #1) for topic Pandemic\n",
      "Downloading book Pandemic: The Beginning (Pandemic #1) for topic Pandemic\n",
      "Downloading book Rush (Pandemic Sorrow, #2) for topic Pandemic\n",
      "Downloading book Pandemic: Tracking Contagions, from Cholera to Ebola and Beyond for topic Pandemic\n",
      "Downloading book Pandemic (The Survivors #1) for topic Pandemic\n",
      "Downloading book Pandemic (The Retreat, #1) for topic Pandemic\n",
      "Downloading book Pandemic (Paul Richter, #2) for topic Pandemic\n",
      "Downloading book Roxy (Pandemic Sorrow, #3) for topic Pandemic\n",
      "Downloading book The Viral Storm: The Dawn of a New Pandemic Age for topic Pandemic\n",
      "Downloading book Beginnings (Pandemic #1) for topic Pandemic\n",
      "Downloading book Frozen Pandemic: Apocalypse for topic Pandemic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>language_code</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>is_ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34811896</td>\n",
       "      <td>[A.G. Riddle]</td>\n",
       "      <td>Pandemic (The Extinction Files, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.03</td>\n",
       "      <td>18609</td>\n",
       "      <td>&lt;b&gt;Around the world, a deadly outbreak spreads...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18211018</td>\n",
       "      <td>[Yvonne Ventresca]</td>\n",
       "      <td>Pandemic</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.78</td>\n",
       "      <td>766</td>\n",
       "      <td>Even under the most normal circumstances, high...</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8087710</td>\n",
       "      <td>[Scott Sigler]</td>\n",
       "      <td>Pandemic (Infected, #3)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4035</td>\n",
       "      <td>&lt;b&gt;The explosive conclusion to the New York Ti...</td>\n",
       "      <td>592</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17573681</td>\n",
       "      <td>[David Quammen]</td>\n",
       "      <td>Spillover: Animal Infections and the Next Huma...</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.30</td>\n",
       "      <td>4952</td>\n",
       "      <td>&lt;strong&gt;“Science writing as detective story at...</td>\n",
       "      <td>592</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29036</td>\n",
       "      <td>[John M. Barry]</td>\n",
       "      <td>The Great Influenza: The Story of the Deadlies...</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.96</td>\n",
       "      <td>17569</td>\n",
       "      <td>At the height of WWI, history’s most lethal in...</td>\n",
       "      <td>546</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23208864</td>\n",
       "      <td>[Stevie J. Cole]</td>\n",
       "      <td>Jag (Pandemic Sorrow, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1501</td>\n",
       "      <td>WARNING: This novel contains explicit language...</td>\n",
       "      <td>379</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9632773</td>\n",
       "      <td>[Steven Konkoly]</td>\n",
       "      <td>The Jakarta Pandemic (The Perseid Collapse, #0.5)</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.88</td>\n",
       "      <td>5401</td>\n",
       "      <td>In the late fall of 2013, a lethal pandemic vi...</td>\n",
       "      <td>396</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36674219</td>\n",
       "      <td>[Robin Cook]</td>\n",
       "      <td>Pandemic (Jack Stapleton &amp; Laurie Montgomery, ...</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2223</td>\n",
       "      <td>&lt;b&gt;&lt;i&gt;New York Times&lt;/i&gt;-bestselling author Ro...</td>\n",
       "      <td>386</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19160666</td>\n",
       "      <td>[A.R. Shaw]</td>\n",
       "      <td>The China Pandemic (Graham's Resolution #1)</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1383</td>\n",
       "      <td>A pandemic virus has struck from China. &lt;br /&gt;...</td>\n",
       "      <td>311</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>710698</td>\n",
       "      <td>[Daniel Kalla]</td>\n",
       "      <td>Pandemic (Dr. Noah Haldane, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1242</td>\n",
       "      <td>&lt;b&gt;Genesis of a Plague&lt;/b&gt;&lt;br /&gt;&lt;br /&gt;Right no...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>45153728</td>\n",
       "      <td>[Christine Kersey]</td>\n",
       "      <td>Pandemic: The Beginning (Pandemic #1)</td>\n",
       "      <td>None</td>\n",
       "      <td>4.24</td>\n",
       "      <td>94</td>\n",
       "      <td>&lt;b&gt; If you like The Walking Dead but don't lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23379998</td>\n",
       "      <td>[Stevie J. Cole]</td>\n",
       "      <td>Rush (Pandemic Sorrow, #2)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.00</td>\n",
       "      <td>291</td>\n",
       "      <td>It’s my job to play music, to make girls wet, ...</td>\n",
       "      <td>231</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23847947</td>\n",
       "      <td>[Sonia Shah]</td>\n",
       "      <td>Pandemic: Tracking Contagions, from Cholera to...</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.96</td>\n",
       "      <td>1539</td>\n",
       "      <td>Scientists agree that a pathogen is likely to ...</td>\n",
       "      <td>288</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37830148</td>\n",
       "      <td>[Alex Burns]</td>\n",
       "      <td>Pandemic (The Survivors #1)</td>\n",
       "      <td>None</td>\n",
       "      <td>4.05</td>\n",
       "      <td>87</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18892050</td>\n",
       "      <td>[Craig DiLouie, Joe McKinney, Stephen Knight, ...</td>\n",
       "      <td>Pandemic (The Retreat, #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>3.88</td>\n",
       "      <td>544</td>\n",
       "      <td>The first episode in a new novella series by a...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2989650</td>\n",
       "      <td>[James Barrington, Peter Stuart Smith]</td>\n",
       "      <td>Pandemic (Paul Richter, #2)</td>\n",
       "      <td>None</td>\n",
       "      <td>4.18</td>\n",
       "      <td>102</td>\n",
       "      <td>The second high-adrenalin, techno-espionage in...</td>\n",
       "      <td>496</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>25190788</td>\n",
       "      <td>[Stevie J. Cole]</td>\n",
       "      <td>Roxy (Pandemic Sorrow, #3)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.31</td>\n",
       "      <td>155</td>\n",
       "      <td>Standalone in the rock star romance series, Pa...</td>\n",
       "      <td>326</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11129776</td>\n",
       "      <td>[Nathan Wolfe]</td>\n",
       "      <td>The Viral Storm: The Dawn of a New Pandemic Age</td>\n",
       "      <td>None</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1621</td>\n",
       "      <td>&lt;b&gt;Dynamic young Stanford biologist Nathan Wol...</td>\n",
       "      <td>320</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35163233</td>\n",
       "      <td>[Bobby Akart]</td>\n",
       "      <td>Beginnings (Pandemic #1)</td>\n",
       "      <td>eng</td>\n",
       "      <td>4.26</td>\n",
       "      <td>734</td>\n",
       "      <td>None</td>\n",
       "      <td>392</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43550764</td>\n",
       "      <td>[Chris Berkness]</td>\n",
       "      <td>Frozen Pandemic: Apocalypse</td>\n",
       "      <td>None</td>\n",
       "      <td>4.11</td>\n",
       "      <td>142</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    goodreads_book_id                                            authors  \\\n",
       "0            34811896                                      [A.G. Riddle]   \n",
       "1            18211018                                 [Yvonne Ventresca]   \n",
       "2             8087710                                     [Scott Sigler]   \n",
       "3            17573681                                    [David Quammen]   \n",
       "4               29036                                    [John M. Barry]   \n",
       "5            23208864                                   [Stevie J. Cole]   \n",
       "6             9632773                                   [Steven Konkoly]   \n",
       "7            36674219                                       [Robin Cook]   \n",
       "8            19160666                                        [A.R. Shaw]   \n",
       "9              710698                                     [Daniel Kalla]   \n",
       "10           45153728                                 [Christine Kersey]   \n",
       "11           23379998                                   [Stevie J. Cole]   \n",
       "12           23847947                                       [Sonia Shah]   \n",
       "13           37830148                                       [Alex Burns]   \n",
       "14           18892050  [Craig DiLouie, Joe McKinney, Stephen Knight, ...   \n",
       "15            2989650             [James Barrington, Peter Stuart Smith]   \n",
       "16           25190788                                   [Stevie J. Cole]   \n",
       "17           11129776                                     [Nathan Wolfe]   \n",
       "18           35163233                                      [Bobby Akart]   \n",
       "19           43550764                                   [Chris Berkness]   \n",
       "\n",
       "                                                title language_code  \\\n",
       "0                 Pandemic (The Extinction Files, #1)           eng   \n",
       "1                                            Pandemic           eng   \n",
       "2                             Pandemic (Infected, #3)           eng   \n",
       "3   Spillover: Animal Infections and the Next Huma...           eng   \n",
       "4   The Great Influenza: The Story of the Deadlies...           eng   \n",
       "5                           Jag (Pandemic Sorrow, #1)           eng   \n",
       "6   The Jakarta Pandemic (The Perseid Collapse, #0.5)           eng   \n",
       "7   Pandemic (Jack Stapleton & Laurie Montgomery, ...           eng   \n",
       "8         The China Pandemic (Graham's Resolution #1)         en-US   \n",
       "9                     Pandemic (Dr. Noah Haldane, #1)           eng   \n",
       "10              Pandemic: The Beginning (Pandemic #1)          None   \n",
       "11                         Rush (Pandemic Sorrow, #2)           eng   \n",
       "12  Pandemic: Tracking Contagions, from Cholera to...           eng   \n",
       "13                        Pandemic (The Survivors #1)          None   \n",
       "14                         Pandemic (The Retreat, #1)           eng   \n",
       "15                        Pandemic (Paul Richter, #2)          None   \n",
       "16                         Roxy (Pandemic Sorrow, #3)           eng   \n",
       "17    The Viral Storm: The Dawn of a New Pandemic Age          None   \n",
       "18                           Beginnings (Pandemic #1)           eng   \n",
       "19                        Frozen Pandemic: Apocalypse          None   \n",
       "\n",
       "    average_rating  ratings_count  \\\n",
       "0             4.03          18609   \n",
       "1             3.78            766   \n",
       "2             4.22           4035   \n",
       "3             4.30           4952   \n",
       "4             3.96          17569   \n",
       "5             3.93           1501   \n",
       "6             3.88           5401   \n",
       "7             3.30           2223   \n",
       "8             4.01           1383   \n",
       "9             3.75           1242   \n",
       "10            4.24             94   \n",
       "11            4.00            291   \n",
       "12            3.96           1539   \n",
       "13            4.05             87   \n",
       "14            3.88            544   \n",
       "15            4.18            102   \n",
       "16            4.31            155   \n",
       "17            3.77           1621   \n",
       "18            4.26            734   \n",
       "19            4.11            142   \n",
       "\n",
       "                                          description  num_pages  is_ebook  \n",
       "0   <b>Around the world, a deadly outbreak spreads...          0      True  \n",
       "1   Even under the most normal circumstances, high...        352     False  \n",
       "2   <b>The explosive conclusion to the New York Ti...        592      True  \n",
       "3   <strong>“Science writing as detective story at...        592     False  \n",
       "4   At the height of WWI, history’s most lethal in...        546     False  \n",
       "5   WARNING: This novel contains explicit language...        379      True  \n",
       "6   In the late fall of 2013, a lethal pandemic vi...        396      True  \n",
       "7   <b><i>New York Times</i>-bestselling author Ro...        386     False  \n",
       "8   A pandemic virus has struck from China. <br />...        311      True  \n",
       "9   <b>Genesis of a Plague</b><br /><br />Right no...          0     False  \n",
       "10  <b> If you like The Walking Dead but don't lik...          0      True  \n",
       "11  It’s my job to play music, to make girls wet, ...        231      True  \n",
       "12  Scientists agree that a pathogen is likely to ...        288     False  \n",
       "13                                               None          0      True  \n",
       "14  The first episode in a new novella series by a...          0      True  \n",
       "15  The second high-adrenalin, techno-espionage in...        496     False  \n",
       "16  Standalone in the rock star romance series, Pa...        326     False  \n",
       "17  <b>Dynamic young Stanford biologist Nathan Wol...        320     False  \n",
       "18                                               None        392      True  \n",
       "19                                               None          0      True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 =h.get_books('Pandemic',strict=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_id', 'goodreads_book_id', 'best_book_id', 'work_id',\n",
       "       'books_count', 'isbn', 'isbn13', 'authors', 'original_publication_year',\n",
       "       'original_title', 'title', 'language_code', 'average_rating',\n",
       "       'ratings_count', 'work_ratings_count', 'work_text_reviews_count',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'image_url', 'small_image_url', 'description', 'num_pages', 'e_book',\n",
       "       'is_ebook'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authors                         0\n",
       "average_rating                  0\n",
       "book_id                       136\n",
       "description                     0\n",
       "goodreads_book_id               0\n",
       "is_ebook                     2269\n",
       "language_code                  52\n",
       "num_pages                       0\n",
       "original_publication_year     136\n",
       "publication_timeframe         136\n",
       "ratings_count                   0\n",
       "title                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### How many of the  columns are missing data ?\n",
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    7391\n",
       "True      440\n",
       "Name: is_ebook, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['is_ebook'].fillna(False)\n",
    "books['is_ebook'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'original_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_title'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cc2647b7dc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(books)}, {len(books[books['original_title'].isna()])},{len(books[books['original_title'] != books ['title']])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Title seems to be including original title in all these cases, we are going to drop original_title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbooks\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'goodreads_book_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'original_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_title'"
     ]
    }
   ],
   "source": [
    "print(f\"{len(books)}, {len(books[books['original_title'].isna()])},{len(books[books['original_title'] != books ['title']])}\")\n",
    "# Title seems to be including original title in all these cases, we are going to drop original_title\n",
    "books[books['original_title'] != books ['title']][['goodreads_book_id','title','original_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that are not relevant for the recommender\n",
    "# books = books.drop(['best_book_id','work_id','isbn13','isbn','original_title',\n",
    "#                     'books_count','work_ratings_count','work_text_reviews_count',\n",
    "#                     'image_url','small_image_url'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### If the book description was empty ,  adding a string so that  Vecotrizer can  work with the data\n",
    "books['description'] = books['description'].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10100.000000\n",
       "mean      1952.678614\n",
       "std        276.200699\n",
       "min          0.000000\n",
       "25%       1989.000000\n",
       "50%       2004.000000\n",
       "75%       2011.000000\n",
       "max       2017.000000\n",
       "Name: original_publication_year, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['original_publication_year'] = books['original_publication_year'].fillna(0).astype('int')\n",
    "books['original_publication_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eng      8778\n",
       "other    1322\n",
       "Name: language_code, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['language_code'] = books['language_code'].apply(lambda x : 'eng' if x in  ['eng','en-US','en-GB','en-CA'] else 'other')\n",
    "books['language_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3          3110\n",
       "4          2547\n",
       "1          1580\n",
       "2          1353\n",
       "0           808\n",
       "5           514\n",
       "unknown     188\n",
       "Name: publication_timeframe, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.loc[books['original_publication_year'] <0,'original_publication_year'] =0\n",
    "def publication_year_categorize(original_publication_year):\n",
    "    if original_publication_year >=2015 :\n",
    "        return('5')\n",
    "    elif original_publication_year >= 2010:\n",
    "        return('4')\n",
    "    elif original_publication_year >= 2000:\n",
    "        return('3')\n",
    "    elif original_publication_year >= 1990:\n",
    "        return('2')\n",
    "    elif original_publication_year >= 1950:\n",
    "        return('1')\n",
    "    elif original_publication_year >= 1:\n",
    "        return('0')\n",
    "    else:\n",
    "         return('unknown')\n",
    "books['publication_timeframe'] =books['original_publication_year'].map(publication_year_categorize)\n",
    "books['publication_timeframe'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Are the books unique ?\n",
    "\n",
    "we have books unique isbn numbers  but  they have similar titles.\n",
    "I am little wary of this data set now. It might  be a good  for proof of concept but  we may need to get cleaner data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate book count = 24\n"
     ]
    }
   ],
   "source": [
    "#De-duplicating the  records as we only care about title and content of the book , \n",
    "books_with_same_title = (books['title'].value_counts()  )\n",
    "print(f\"duplicate book count = {len(books_with_same_title.index[books_with_same_title >1])}\")\n",
    "\n",
    "dup_books =books_with_same_title.index[books_with_same_title >1]\n",
    "dup_book_df = books[books['title'].isin(dup_books)]\n",
    "\n",
    "books = books.groupby('title').agg(\n",
    "                             {\n",
    "                              'book_id':'first',\n",
    "                              'goodreads_book_id':'first',\n",
    "                              'authors':'first', \n",
    "                              'description' :'first',\n",
    "                              'original_publication_year': 'first',\n",
    "                              'language_code' :'first',\n",
    "                              'average_rating':'mean',\n",
    "                              'ratings_count': 'sum',                              \n",
    "                              'num_pages':'first',\n",
    "                              'is_ebook':'first',\n",
    "                              'ratings_count':'first',\n",
    "                              'publication_timeframe':'first'\n",
    "                              }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"../data/books_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Book Tags preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tags = pd.read_csv(\"../data/book_tags_combined.csv\")\n",
    "###### Consolidate all Audio tags under same category\n",
    "def consolidate_tags(tag_lst,target_tag):\n",
    "    target_tag_id = book_tags[book_tags['tag_name']==target_tag]['tag_id'].values[0]  \n",
    "    l= book_tags[(book_tags['tag_name'].isin(tag_lst))]['tag_name'].to_list()\n",
    "    print(f\"replacing {len(l)} tags with {target_tag}, tag_id= {target_tag_id}\")\n",
    "    book_tags['tag_name']= book_tags['tag_name'].apply(lambda x : target_tag if x in tag_lst else x)\n",
    "    book_tags.loc[book_tags['tag_name'] ==target_tag,'tag_id']= target_tag_id \n",
    "consolidate_tags(['teen','juvenile','youth','new-adult'],'young-adult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Consolidate all childrens books under same category\n",
    "tag_lst= book_tags[(book_tags['tag_name'].str.contains('children')) ]['tag_name'].to_list()\n",
    "#consolidate_tags(['childhood-reads','kids','kids-books','childhood-books','childhood','childhood-favorites'],'childrens')\n",
    "#consolidate_tags(list(set(tag_lst)),'childrens')\n",
    "\n",
    "\n",
    "\n",
    "#tag_lst = book_tags[(book_tags['tag_name'].str.contains('history'))]['tag_name'].to_list()\n",
    "#consolidate_tags(set(['war'] +tag_lst),'history')\n",
    "\n",
    "#suspense\n",
    "consolidate_tags(['suspense-thriller','thriller-mystery','thriller-suspense','mystery-thrillers','epic-fantasy','mystery-suspense-thriller','mystery-thriller-suspense'],'mystery-thriller')\n",
    "#tag_lst= book_tags[(book_tags['tag_name'].str.contains('mystery'))]['tag_name'].to_list()\n",
    "#consolidate_tags(tag_lst,'mystery-thriller')\n",
    "\n",
    "\n",
    "tag_lst=set(book_tags[(book_tags['tag_name'].str.contains('novel'))]['tag_name'].to_list())\n",
    "consolidate_tags(tag_lst,'novels')\n",
    "\n",
    "tag_lst=set(book_tags[(book_tags['tag_name'].str.contains('memoir'))]['tag_name'].to_list())\n",
    "consolidate_tags(tag_lst,'biography')\n",
    "\n",
    "## Fiction\n",
    "consolidate_tags(['teen','juvenile','youth','new-adult'],'young-adult')\n",
    "consolidate_tags(['general-fiction','speculative-fiction','magic','literary-fiction','contemporary-fiction','modern-fiction','vampires','vampire','fiction-to-read'],'fiction')\n",
    "consolidate_tags(['ya-fiction','harry-potter'],'fiction') \n",
    "#consolidate_tags(['sci-fi','scifi'],'science-fiction')\n",
    "consolidate_tags(['teen-fiction','juvenile-fiction'],'young-adult-fiction')\n",
    "\n",
    "\n",
    "consolidate_tags(['paranormal','paranormal-romance','paranormal-fantasy','fantasy-paranormal'],'supernatural') \n",
    "\n",
    "#consolidate_tags(['fantasy-sci-fi,sci-fi-fantasy','science-fiction-fantasy','fantasy-scifi','sci-fi-and-fantasy'],'scifi-fantasy') \n",
    "consolidate_tags(['urban-fantasy','ya-fantasy','high-fantasy','sf-fantasy','guilty-pleasures'],'fantasy')\n",
    "\n",
    "consolidate_tags(['funny','humour','comedy','humorous'],'humor') \n",
    "consolidate_tags(['20th-century','19th-century','historicals'],'historical') \n",
    " \n",
    "consolidate_tags(['non-fiction','to-read-nonfiction','non-fic','nonfiction-to-read'],'nonfiction') \n",
    "consolidate_tags(['to-read-non-fiction','non-fiction-to-read'],'nonfiction') \n",
    "\n",
    "\n",
    "consolidate_tags(['thrillers'],'thriller')\n",
    "\n",
    "\n",
    "consolidate_tags(['contemporary-romance'],'romance')\n",
    "consolidate_tags(['urban-fantasy','ya-fantasy'],'fantasy')\n",
    "\n",
    "\n",
    "\n",
    "consolidate_tags(['classic','literature','literary','classics','american-lit','american-literature','british-literature','chic-lit','kid-lit','chicklit','to-read-classics'],'classic-literature') \n",
    "consolidate_tags(['dystopia'],'dystopian')\n",
    "\n",
    "\n",
    "\n",
    "consolidate_tags(['realistic'],'realistic-fiction')\n",
    "consolidate_tags(['erotica','erotic'],'adult-romance')\n",
    "consolidate_tags(['modern'],'contemporary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_tags = pd.read_csv(\"../data/book_tags_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  references\n",
    "https://pypi.org/project/Goodreads/\n",
    "\n",
    "https://betterreads.readthedocs.io/en/latest/\n",
    "\n",
    "Kaggle data source : https://www.kaggle.com/zygmunt/goodbooks-10k\n",
    "\n",
    "data set location : https://github.com/zygmuntz/goodbooks-10k\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
