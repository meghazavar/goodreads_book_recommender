{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Installing and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: betterreads in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (0.4.2)\n",
      "Requirement already satisfied: rauth in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages/rauth-0.7.3-py3.7.egg (from betterreads) (0.7.3)\n",
      "Requirement already satisfied: requests in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from betterreads) (2.22.0)\n",
      "Requirement already satisfied: backports-datetime-fromisoformat in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from betterreads) (1.0.0)\n",
      "Requirement already satisfied: xmltodict in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages/xmltodict-0.12.0-py3.7.egg (from betterreads) (0.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages (from requests->betterreads) (2.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install betterreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data... \n",
      "[   10    11    12 ...  9998  9999 10000]\n",
      "getting 10 out of missing 9991 descriptions\n",
      "10,Pride and Prejudice\n",
      "saving the results to the file....\n",
      "11,The Kite Runner\n",
      "12,Divergent (Divergent, #1)\n",
      "13,1984\n",
      "14,Animal Farm\n",
      "15,The Diary of a Young Girl\n",
      "16,The Girl with the Dragon Tattoo (Millennium, #1)\n",
      "17,Catching Fire (The Hunger Games, #2)\n",
      "18,Harry Potter and the Prisoner of Azkaban (Harry Potter, #3)\n",
      "19,The Fellowship of the Ring (The Lord of the Rings, #1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from betterreads import client\n",
    "from goodreads_data_gather import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering data... \n"
     ]
    }
   ],
   "source": [
    "h = helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note : Only run this very first run so we can get the orginal books set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('../data/books.csv')\n",
    "print( f\"shape of the books dataframe is {books.shape}\")\n",
    "#We are going to add. 3 more columns and populate them using the GoodReads client\n",
    "books['description'] =np.nan\n",
    "books['num_pages'] =0\n",
    "books['e_book'] =False\n",
    "books.to_csv(\"../data/books_desc.csv\", index=False)\n",
    "books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the ratings dataframe is (5976479, 3)\n",
      "shape of the books_tags dataframe is (999912, 3)\n",
      "shape of the tags dataframe is (34252, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>e_book</th>\n",
       "      <th>is_ebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "      <td>Could you survive on your own, in the wild, wi...</td>\n",
       "      <td>374</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  goodreads_book_id  best_book_id  work_id  books_count       isbn  \\\n",
       "0        1            2767052       2767052  2792775          272  439023483   \n",
       "\n",
       "         isbn13          authors  original_publication_year    original_title  \\\n",
       "0  9.780439e+12  Suzanne Collins                     2008.0  The Hunger Games   \n",
       "\n",
       "   ... ratings_2 ratings_3  ratings_4  ratings_5  \\\n",
       "0  ...    127936    560092    1481305    2706317   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "\n",
       "                                     small_image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603s...   \n",
       "\n",
       "                                         description  num_pages  e_book  \\\n",
       "0  Could you survive on your own, in the wild, wi...        374   False   \n",
       "\n",
       "   is_ebook  \n",
       "0     False  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books =pd.read_csv(\"../data/books_desc.csv\")\n",
    "\n",
    "ratings = pd.read_csv(\"../data/ratings.csv\")\n",
    "print( f\"shape of the ratings dataframe is {ratings.shape}\")\n",
    "\n",
    "book_tags = pd.read_csv(\"../data/book_tags.csv\")\n",
    "print( f\"shape of the books_tags dataframe is {book_tags.shape}\")\n",
    "\n",
    "tags = pd.read_csv(\"../data/tags.csv\")\n",
    "print( f\"shape of the tags dataframe is {tags.shape}\")\n",
    "\n",
    "### Combining booktag ids with the actual names\n",
    "pd.merge(left=book_tags,right =tags, how =\"left\", on ='tag_id')\n",
    "book_tags.to_csv(\"../data/book_tags_combined\",index =False)\n",
    "books.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_id</th>\n",
       "      <th>tag_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag_id tag_name\n",
       "0       0        -"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodreads_book_id</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30574</td>\n",
       "      <td>167697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   goodreads_book_id  tag_id   count\n",
       "0                  1   30574  167697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_tags.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We are going to populate description , num_of_pages and is_ebook from goodreads Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   10    11    12 ...  9998  9999 10000]\n",
      "getting 10 out of missing 9991 descriptions\n",
      "10,Pride and Prejudice\n",
      "saving the results to the file....\n",
      "11,The Kite Runner\n",
      "12,Divergent (Divergent, #1)\n",
      "13,1984\n",
      "14,Animal Farm\n",
      "15,The Diary of a Young Girl\n",
      "16,The Girl with the Dragon Tattoo (Millennium, #1)\n",
      "17,Catching Fire (The Hunger Games, #2)\n",
      "18,Harry Potter and the Prisoner of Azkaban (Harry Potter, #3)\n",
      "19,The Fellowship of the Ring (The Lord of the Rings, #1)\n"
     ]
    }
   ],
   "source": [
    "books =h.fill_missing_columns(\"../data/books_desc.csv\",10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "585 books that are missing orig title, replace them with title\n",
    "book = gc.book(3)\n",
    "book.original_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting  recent books  based on Denver DSI classmates reading preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mybiyani/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "collect_books = pd.DataFrame()\n",
    "topics =['python','of Thrones','Patrick Rothfuss','A Song of Ice and Fire','Inspector Rebus',\n",
    "      'Data Science', 'mechine learning','Data Visualization','Robert T. Kiyosaki','Brené Brown',\n",
    "      'weapons of math destruction','Girl, Wash Your Face','recommender systems']\n",
    "for topic in topics :\n",
    "    df2 =h.get_books(topic)\n",
    "    books = pd.concat([books,df2],sort=True)\n",
    "books.reset_index(inplace=True, drop=True)  \n",
    "books.to_csv(\"../data/books_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['authors', 'average_rating', 'book_id', 'description', 'e_book',\n",
       "       'goodreads_book_id', 'is_ebook', 'language_code', 'num_pages',\n",
       "       'original_publication_year', 'ratings_1', 'ratings_2', 'ratings_3',\n",
       "       'ratings_4', 'ratings_5', 'ratings_count', 'title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authors                         0\n",
       "average_rating                  0\n",
       "book_id                       138\n",
       "description                  9981\n",
       "e_book                        138\n",
       "goodreads_book_id               0\n",
       "is_ebook                     9981\n",
       "language_code                1138\n",
       "num_pages                       0\n",
       "original_publication_year     159\n",
       "ratings_1                     138\n",
       "ratings_2                     138\n",
       "ratings_3                     138\n",
       "ratings_4                     138\n",
       "ratings_5                     138\n",
       "ratings_count                   0\n",
       "title                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### How many of the  columns are missing data ?\n",
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'original_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_title'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cc2647b7dc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{len(books)}, {len(books[books['original_title'].isna()])},{len(books[books['original_title'] != books ['title']])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Title seems to be including original title in all these cases, we are going to drop original_title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbooks\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'goodreads_book_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'original_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'original_title'"
     ]
    }
   ],
   "source": [
    "print(f\"{len(books)}, {len(books[books['original_title'].isna()])},{len(books[books['original_title'] != books ['title']])}\")\n",
    "# Title seems to be including original title in all these cases, we are going to drop original_title\n",
    "books[books['original_title'] != books ['title']][['goodreads_book_id','title','original_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that are not relevant for the recommender\n",
    "# books = books.drop(['best_book_id','work_id','isbn13','isbn','original_title',\n",
    "#                     'books_count','work_ratings_count','work_text_reviews_count',\n",
    "#                     'image_url','small_image_url'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### If the book description was empty ,  adding a string so that  Vecotrizer can  work with the data\n",
    "books['description'] = books['description'].fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['original_publication_year'] = books['original_publication_year'].fillna(0).astype('int')\n",
    "books['original_publication_year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books['language_code'] = books['language_code'].apply(lambda x : 'eng' if x in  ['eng','en-US','en-GB','en-CA'] else 'other')\n",
    "books['language_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.loc[books['original_publication_year'] <0,'original_publication_year'] =0\n",
    "def publication_year_categorize(original_publication_year):\n",
    "    if original_publication_year >=2015 :\n",
    "        return('2015-2020')\n",
    "    elif original_publication_year >= 2010:\n",
    "        return('2010-2014')\n",
    "    elif original_publication_year >= 2000:\n",
    "        return('2000-2013')\n",
    "    elif original_publication_year >= 1990:\n",
    "        return('1990-2000')\n",
    "    elif original_publication_year >= 1950:\n",
    "        return('1950-1990')\n",
    "    elif original_publication_year >= 1:\n",
    "        return('<1950')\n",
    "    else:\n",
    "         return('unknown')\n",
    "books['publication_timeframe'] =books['original_publication_year'].map(publication_year_categorize)\n",
    "books['publication_timeframe'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Are the books unique ?\n",
    "\n",
    "we have books unique isbn numbers  but  they have similar titles.\n",
    "I am little wary of this data set now. It might  be a good  for proof of concept but  we may need to get cleaner data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate book count = 163\n"
     ]
    }
   ],
   "source": [
    "#De-duplicating the  records as we only care about title and content of the book , \n",
    "books_with_same_title = (books['title'].value_counts()  )\n",
    "print(f\"duplicate book count = {len(books_with_same_title.index[books_with_same_title >1])}\")\n",
    "\n",
    "dup_books =books_with_same_title.index[books_with_same_title >1]\n",
    "dup_book_df = books[books['title'].isin(dup_books)]\n",
    "\n",
    "books = books.groupby('title').agg(\n",
    "                             {\n",
    "                              'book_id':'first',\n",
    "                              'goodreads_book_id':'first',\n",
    "                              'authors':'first', \n",
    "                              'description' :'first',\n",
    "                              'original_publication_year': 'first',\n",
    "                              'language_code' :'first',\n",
    "                              'average_rating':'mean',\n",
    "                              'ratings_count': 'sum',                              \n",
    "                              'num_pages':'first',\n",
    "                              'is_ebook':'first',\n",
    "                              'ratings_count':'first'\n",
    "                              }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Consolidate all Audio tags under same category\n",
    "def consolidate_tags(tag_lst,target_tag):\n",
    "    target_tag_id = book_tags[book_tags['tag_name']==target_tag]['tag_id'].values[0]  \n",
    "    l= book_tags[(book_tags['tag_name'].isin(tag_lst))]['tag_name'].to_list()\n",
    "    print(f\"replacing {len(l)} tags with {target_tag}, tag_id= {target_tag_id}\")\n",
    "    book_tags['tag_name']= book_tags['tag_name'].apply(lambda x : target_tag if x in tag_lst else x)\n",
    "    book_tags.loc[book_tags['tag_name'] ==target_tag,'tag_id']= target_tag_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Consolidate all childrens books under same category\n",
    "#tag_lst= book_tags[(book_tags['tag_name'].str.contains('children')) ]['tag_name'].to_list()\n",
    "#consolidate_tags(list(set(tag_lst)),'childrens')\n",
    "\n",
    "#tag_lst= ['audio','audiobooks','audiobook','audible','audio-book','audio-books'] +(book_tags[(book_tags['tag_name'].str.contains('audiobook'))]['tag_name'].to_list())\n",
    "#consolidate_tags(set(tag_lst),'audiobook')\n",
    "\n",
    "# tag_lst = book_tags[(book_tags['tag_name'].str.contains('history'))]['tag_name'].to_list()\n",
    "# consolidate_tags(set(['war'] +tag_lst),'history')\n",
    "\n",
    "#suspense\n",
    "# tag_lst= book_tags[(book_tags['tag_name'].str.contains('mystery'))]['tag_name'].to_list()\n",
    "# consolidate_tags(tag_lst,'mystery-thriller')\n",
    "\n",
    "\n",
    "# tag_lst=set(book_tags[(book_tags['tag_name'].str.contains('novel'))]['tag_name'].to_list())\n",
    "# consolidate_tags(tag_lst,'novels')\n",
    "\n",
    "# consolidate_tags(['teen','juvenile','youth','new-adult'],'young-adult')\n",
    "# consolidate_tags(['general-fiction','speculative-fiction','magic','literary-fiction','contemporary-fiction','modern-fiction','vampires','vampire','fiction-to-read'],'fiction')\n",
    "# consolidate_tags(['paranormal','paranormal-romance','paranormal-fantasy','fantasy-paranormal'],'supernatural') \n",
    "# consolidate_tags(['fantasy-sci-fi,sci-fi-fantasy','science-fiction-fantasy','fantasy-scifi','sci-fi-and-fantasy'],'scifi-fantasy') \n",
    "# consolidate_tags(['funny','humour','comedy','humorous'],'humor') \n",
    "# consolidate_tags(['20th-century','19th-century','historicals'],'historical') \n",
    "# consolidate_tags(['sci-fi','scifi'],'science-fiction') \n",
    "\n",
    "#consolidate_tags(['non-fiction','to-read-nonfiction','non-fic','nonfiction-to-read'],'nonfiction') \n",
    "#consolidate_tags(['ya-fiction','harry-potter'],'fiction') \n",
    "\n",
    "# consolidate_tags(['urban-fantasy','ya-fantasy','high-fantasy','sf-fantasy','guilty-pleasures'],'fantasy')\n",
    "# consolidate_tags(['thrillers'],'thriller')\n",
    "# consolidate_tags(['childhood-reads','kids','kids-books','childhood-books','childhood','childhood-favorites'],'childrens')\n",
    "# consolidate_tags(['listened-to'],'audiobook')\n",
    "# consolidate_tags(['to-read-non-fiction','non-fiction-to-read'],'nonfiction') \n",
    "# consolidate_tags(['contemporary-romance'],'romance')\n",
    "# consolidate_tags(['urban-fantasy','ya-fantasy'],'fantasy')\n",
    "\n",
    "\n",
    "# tag_lst=set(book_tags[(book_tags['tag_name'].str.contains('memoir'))]['tag_name'].to_list())\n",
    "# consolidate_tags(tag_lst,'biography')\n",
    "\n",
    "# consolidate_tags(['teen-fiction','juvenile-fiction'],'young-adult-fiction')\n",
    "# consolidate_tags(['classic','literature','literary','classics','american-lit','american-literature','british-literature','chic-lit','kid-lit','chicklit','to-read-classics'],'classic-literature') \n",
    "# consolidate_tags(['dystopia'],'dystopian')\n",
    "\n",
    "\n",
    "\n",
    "# consolidate_tags(['realistic'],'realistic-fiction')\n",
    "# consolidate_tags(['erotica','erotic'],'adult-romance')\n",
    "# consolidate_tags(['modern'],'contemporary')\n",
    "consolidate_tags(['suspense-thriller','thriller-mystery','thriller-suspense','mystery-thrillers','epic-fantasy','mystery-suspense-thriller','mystery-thriller-suspense'],'mystery-thriller')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"../data/books_desc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  references\n",
    "https://pypi.org/project/Goodreads/\n",
    "\n",
    "https://betterreads.readthedocs.io/en/latest/\n",
    "\n",
    "Kaggle data source : https://www.kaggle.com/zygmunt/goodbooks-10k\n",
    "\n",
    "data set location : https://github.com/zygmuntz/goodbooks-10k\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
